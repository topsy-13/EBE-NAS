{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e8489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import epoch_based_evolution as ebe\n",
    "import load_data as ld # for loading and transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa39cd7",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc76447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features detected: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V44', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V57', 'V58', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V128', 'V129', 'V130', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144']\n",
      "Class column is not numeric. Applying LabelEncoder.\n",
      "Data loaded successfully! Format: tensor\n",
      "Training data shape: torch.Size([1909, 280])\n"
     ]
    }
   ],
   "source": [
    "DATA_ID = 41143\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = ld.get_preprocessed_data(\n",
    "        dataset_id=DATA_ID, scaling=True, random_seed=13, return_as='tensor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501cba7",
   "metadata": {},
   "source": [
    "# EBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21420aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input and output sizes are needed for the model, these are integers\n",
    "input_size, output_size = ld.get_tensor_sizes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a44bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The search space for the architectures is defined here, \n",
    "# possible arguments can be modified, check the class definition\n",
    "\n",
    "search_space = ebe.SearchSpace(input_size=input_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34c67cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INDIVIDUALS = 100 # amount of architectures to be evaluated as a starting point\n",
    "N_EPOCHS = 5 \n",
    "percentile_drop = 25 # drop the worst 25% of architectures after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f27335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generation is created given the search space and the number of individuals.\n",
    "generation = ebe.Generation(search_space, N_INDIVIDUALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb16863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 2/5\n",
      "Epoch 3/5\n",
      "Epoch 4/5\n",
      "Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "generation.run_ebe(n_epochs=N_EPOCHS,\n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    X_val=X_val,\n",
    "                    y_val=y_val, percentile_drop=percentile_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97910ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hidden_layers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "activation_fn",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "dropout_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "optimizer_type",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "learning_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weight_decay",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "momentum",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "batch_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "use_skip_connections",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "initializer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lr_scheduler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scheduler_params",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9ac24400-acc1-4621-92c6-c3ad92bff636",
       "rows": [
        [
         "0",
         "[311, 52, 292, 134, 237, 51]",
         "<class 'torch.nn.modules.activation.ReLU'>",
         "0.2",
         "<class 'torch.optim.rmsprop.RMSprop'>",
         "0.0008118476561469561",
         "0.001",
         null,
         "512",
         "True",
         "kaiming_uniform",
         "cosine",
         "{'T_max': 50}",
         "0.40530703331925844",
         "0.8056574122577266",
         "0.44984084367752075",
         "0.7656903765690377"
        ],
        [
         "1",
         "[386, 313, 24, 355, 91, 227]",
         "<class 'torch.nn.modules.activation.Sigmoid'>",
         "0.3",
         "<class 'torch.optim.adam.Adam'>",
         "0.0035501893833228414",
         "1e-06",
         null,
         "64",
         "True",
         "xavier_uniform",
         "step",
         "{'step_size': 20, 'gamma': 0.5}",
         "0.4449362497856756",
         "0.8019905709795705",
         "0.46274394058782187",
         "0.7635983263598326"
        ],
        [
         "2",
         "[123, 318, 193]",
         "<class 'torch.nn.modules.activation.Tanh'>",
         "0.5",
         "<class 'torch.optim.sgd.SGD'>",
         "0.01888414408860807",
         "1e-06",
         "0.8",
         "512",
         "True",
         "kaiming_normal",
         "step",
         "{'step_size': 20, 'gamma': 0.1}",
         "0.5810489288295608",
         "0.6883184913567313",
         "0.48062342405319214",
         "0.7635983263598326"
        ],
        [
         "3",
         "[416, 486, 246, 511, 413, 165]",
         "<class 'torch.nn.modules.activation.ReLU'>",
         "0.4",
         "<class 'torch.optim.rmsprop.RMSprop'>",
         "0.00021157007147045822",
         "0.0001",
         null,
         "32",
         "False",
         "xavier_normal",
         "none",
         "{}",
         "0.42718695237600346",
         "0.7967522262964903",
         "0.43681867850874256",
         "0.7594142259414226"
        ],
        [
         "4",
         "[410, 475, 458, 404, 406, 283]",
         "<class 'torch.nn.modules.activation.LeakyReLU'>",
         "0.2",
         "<class 'torch.optim.adamw.AdamW'>",
         "0.0002279370405507212",
         "0.0",
         null,
         "256",
         "True",
         "kaiming_normal",
         "none",
         "{}",
         "0.4970914293734299",
         "0.7579884756416972",
         "0.45968513122163557",
         "0.7573221757322176"
        ],
        [
         "5",
         "[298, 419, 41, 166, 114]",
         "<class 'torch.nn.modules.activation.ELU'>",
         "0.0",
         "<class 'torch.optim.adam.Adam'>",
         "0.003956468942179006",
         "0.01",
         null,
         "128",
         "False",
         "kaiming_uniform",
         "none",
         "{}",
         "0.3958168867497372",
         "0.8056574122577266",
         "0.4582389742759481",
         "0.7573221757322176"
        ],
        [
         "6",
         "[224, 317, 235, 193, 153, 87, 312]",
         "<class 'torch.nn.modules.activation.ELU'>",
         "0.3",
         "<class 'torch.optim.adamw.AdamW'>",
         "0.00039841972428913356",
         "0.0001",
         null,
         "64",
         "False",
         "kaiming_normal",
         "exponential",
         "{'gamma': 0.95}",
         "0.5998519065181518",
         "0.7223677317967522",
         "0.46331959551348345",
         "0.7552301255230126"
        ],
        [
         "7",
         "[155, 381]",
         "<class 'torch.nn.modules.activation.ELU'>",
         "0.3",
         "<class 'torch.optim.adam.Adam'>",
         "0.0010876177618100746",
         "0.001",
         null,
         "32",
         "False",
         "xavier_normal",
         "cosine",
         "{'T_max': 100}",
         "0.39127433813636125",
         "0.8082765845992667",
         "0.4612460041644683",
         "0.7552301255230126"
        ],
        [
         "8",
         "[140, 509, 271, 134]",
         "<class 'torch.nn.modules.activation.LeakyReLU'>",
         "0.3",
         "<class 'torch.optim.adam.Adam'>",
         "0.00023297993731527828",
         "0.01",
         null,
         "64",
         "False",
         "xavier_uniform",
         "exponential",
         "{'gamma': 0.9}",
         "0.46016826022039725",
         "0.7689889994761655",
         "0.45232951815657035",
         "0.7531380753138075"
        ],
        [
         "9",
         "[351, 472]",
         "<class 'torch.nn.modules.activation.LeakyReLU'>",
         "0.0",
         "<class 'torch.optim.adam.Adam'>",
         "0.01501470581248169",
         "0.01",
         null,
         "64",
         "True",
         "kaiming_normal",
         "exponential",
         "{'gamma': 0.99}",
         "0.45616462150751574",
         "0.7778941854374017",
         "0.4628805844853613",
         "0.7510460251046025"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation_fn</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>optimizer_type</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>momentum</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>use_skip_connections</th>\n",
       "      <th>initializer</th>\n",
       "      <th>lr_scheduler</th>\n",
       "      <th>scheduler_params</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[311, 52, 292, 134, 237, 51]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.ReLU'&gt;</td>\n",
       "      <td>0.2</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>cosine</td>\n",
       "      <td>{'T_max': 50}</td>\n",
       "      <td>0.405307</td>\n",
       "      <td>0.805657</td>\n",
       "      <td>0.449841</td>\n",
       "      <td>0.765690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[386, 313, 24, 355, 91, 227]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.Sigmoid'&gt;</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>step</td>\n",
       "      <td>{'step_size': 20, 'gamma': 0.5}</td>\n",
       "      <td>0.444936</td>\n",
       "      <td>0.801991</td>\n",
       "      <td>0.462744</td>\n",
       "      <td>0.763598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[123, 318, 193]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.Tanh'&gt;</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.018884</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_normal</td>\n",
       "      <td>step</td>\n",
       "      <td>{'step_size': 20, 'gamma': 0.1}</td>\n",
       "      <td>0.581049</td>\n",
       "      <td>0.688318</td>\n",
       "      <td>0.480623</td>\n",
       "      <td>0.763598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[416, 486, 246, 511, 413, 165]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.ReLU'&gt;</td>\n",
       "      <td>0.4</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>xavier_normal</td>\n",
       "      <td>none</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.427187</td>\n",
       "      <td>0.796752</td>\n",
       "      <td>0.436819</td>\n",
       "      <td>0.759414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[410, 475, 458, 404, 406, 283]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.LeakyReLU'&gt;</td>\n",
       "      <td>0.2</td>\n",
       "      <td>&lt;class 'torch.optim.adamw.AdamW'&gt;</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_normal</td>\n",
       "      <td>none</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.497091</td>\n",
       "      <td>0.757988</td>\n",
       "      <td>0.459685</td>\n",
       "      <td>0.757322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[298, 419, 41, 166, 114]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.ELU'&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>none</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.395817</td>\n",
       "      <td>0.805657</td>\n",
       "      <td>0.458239</td>\n",
       "      <td>0.757322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[224, 317, 235, 193, 153, 87, 312]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.ELU'&gt;</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'torch.optim.adamw.AdamW'&gt;</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>kaiming_normal</td>\n",
       "      <td>exponential</td>\n",
       "      <td>{'gamma': 0.95}</td>\n",
       "      <td>0.599852</td>\n",
       "      <td>0.722368</td>\n",
       "      <td>0.463320</td>\n",
       "      <td>0.755230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[155, 381]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.ELU'&gt;</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>xavier_normal</td>\n",
       "      <td>cosine</td>\n",
       "      <td>{'T_max': 100}</td>\n",
       "      <td>0.391274</td>\n",
       "      <td>0.808277</td>\n",
       "      <td>0.461246</td>\n",
       "      <td>0.755230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[140, 509, 271, 134]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.LeakyReLU'&gt;</td>\n",
       "      <td>0.3</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>exponential</td>\n",
       "      <td>{'gamma': 0.9}</td>\n",
       "      <td>0.460168</td>\n",
       "      <td>0.768989</td>\n",
       "      <td>0.452330</td>\n",
       "      <td>0.753138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[351, 472]</td>\n",
       "      <td>&lt;class 'torch.nn.modules.activation.LeakyReLU'&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_normal</td>\n",
       "      <td>exponential</td>\n",
       "      <td>{'gamma': 0.99}</td>\n",
       "      <td>0.456165</td>\n",
       "      <td>0.777894</td>\n",
       "      <td>0.462881</td>\n",
       "      <td>0.751046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        hidden_layers  \\\n",
       "0        [311, 52, 292, 134, 237, 51]   \n",
       "1        [386, 313, 24, 355, 91, 227]   \n",
       "2                     [123, 318, 193]   \n",
       "3      [416, 486, 246, 511, 413, 165]   \n",
       "4      [410, 475, 458, 404, 406, 283]   \n",
       "5            [298, 419, 41, 166, 114]   \n",
       "6  [224, 317, 235, 193, 153, 87, 312]   \n",
       "7                          [155, 381]   \n",
       "8                [140, 509, 271, 134]   \n",
       "9                          [351, 472]   \n",
       "\n",
       "                                     activation_fn  dropout_rate  \\\n",
       "0       <class 'torch.nn.modules.activation.ReLU'>           0.2   \n",
       "1    <class 'torch.nn.modules.activation.Sigmoid'>           0.3   \n",
       "2       <class 'torch.nn.modules.activation.Tanh'>           0.5   \n",
       "3       <class 'torch.nn.modules.activation.ReLU'>           0.4   \n",
       "4  <class 'torch.nn.modules.activation.LeakyReLU'>           0.2   \n",
       "5        <class 'torch.nn.modules.activation.ELU'>           0.0   \n",
       "6        <class 'torch.nn.modules.activation.ELU'>           0.3   \n",
       "7        <class 'torch.nn.modules.activation.ELU'>           0.3   \n",
       "8  <class 'torch.nn.modules.activation.LeakyReLU'>           0.3   \n",
       "9  <class 'torch.nn.modules.activation.LeakyReLU'>           0.0   \n",
       "\n",
       "                          optimizer_type  learning_rate  weight_decay  \\\n",
       "0  <class 'torch.optim.rmsprop.RMSprop'>       0.000812      0.001000   \n",
       "1        <class 'torch.optim.adam.Adam'>       0.003550      0.000001   \n",
       "2          <class 'torch.optim.sgd.SGD'>       0.018884      0.000001   \n",
       "3  <class 'torch.optim.rmsprop.RMSprop'>       0.000212      0.000100   \n",
       "4      <class 'torch.optim.adamw.AdamW'>       0.000228      0.000000   \n",
       "5        <class 'torch.optim.adam.Adam'>       0.003956      0.010000   \n",
       "6      <class 'torch.optim.adamw.AdamW'>       0.000398      0.000100   \n",
       "7        <class 'torch.optim.adam.Adam'>       0.001088      0.001000   \n",
       "8        <class 'torch.optim.adam.Adam'>       0.000233      0.010000   \n",
       "9        <class 'torch.optim.adam.Adam'>       0.015015      0.010000   \n",
       "\n",
       "   momentum  batch_size  use_skip_connections      initializer lr_scheduler  \\\n",
       "0       NaN         512                  True  kaiming_uniform       cosine   \n",
       "1       NaN          64                  True   xavier_uniform         step   \n",
       "2       0.8         512                  True   kaiming_normal         step   \n",
       "3       NaN          32                 False    xavier_normal         none   \n",
       "4       NaN         256                  True   kaiming_normal         none   \n",
       "5       NaN         128                 False  kaiming_uniform         none   \n",
       "6       NaN          64                 False   kaiming_normal  exponential   \n",
       "7       NaN          32                 False    xavier_normal       cosine   \n",
       "8       NaN          64                 False   xavier_uniform  exponential   \n",
       "9       NaN          64                  True   kaiming_normal  exponential   \n",
       "\n",
       "                  scheduler_params  train_loss  train_acc  val_loss   val_acc  \n",
       "0                    {'T_max': 50}    0.405307   0.805657  0.449841  0.765690  \n",
       "1  {'step_size': 20, 'gamma': 0.5}    0.444936   0.801991  0.462744  0.763598  \n",
       "2  {'step_size': 20, 'gamma': 0.1}    0.581049   0.688318  0.480623  0.763598  \n",
       "3                               {}    0.427187   0.796752  0.436819  0.759414  \n",
       "4                               {}    0.497091   0.757988  0.459685  0.757322  \n",
       "5                               {}    0.395817   0.805657  0.458239  0.757322  \n",
       "6                  {'gamma': 0.95}    0.599852   0.722368  0.463320  0.755230  \n",
       "7                   {'T_max': 100}    0.391274   0.808277  0.461246  0.755230  \n",
       "8                   {'gamma': 0.9}    0.460168   0.768989  0.452330  0.753138  \n",
       "9                  {'gamma': 0.99}    0.456165   0.777894  0.462881  0.751046  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = generation.return_df()\n",
    "display(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c432e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"activation_fn\"] = results_df[\"activation_fn\"].apply(lambda x: x.__name__)\n",
    "results_df[\"optimizer_type\"] = results_df[\"optimizer_type\"].apply(lambda x: x.__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7144fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hidden_layers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "activation_fn",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dropout_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "optimizer_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "learning_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weight_decay",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "momentum",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "batch_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "use_skip_connections",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "initializer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lr_scheduler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scheduler_params",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7c47923e-c7c5-4b0a-a578-7bc501fa0356",
       "rows": [
        [
         "0",
         "[311, 52, 292, 134, 237, 51]",
         "ReLU",
         "0.2",
         "RMSprop",
         "0.0008118476561469561",
         "0.001",
         null,
         "512",
         "True",
         "kaiming_uniform",
         "cosine",
         "{'T_max': 50}",
         "0.40530703331925844",
         "0.8056574122577266",
         "0.44984084367752075",
         "0.7656903765690377"
        ],
        [
         "1",
         "[386, 313, 24, 355, 91, 227]",
         "Sigmoid",
         "0.3",
         "Adam",
         "0.0035501893833228414",
         "1e-06",
         null,
         "64",
         "True",
         "xavier_uniform",
         "step",
         "{'step_size': 20, 'gamma': 0.5}",
         "0.4449362497856756",
         "0.8019905709795705",
         "0.46274394058782187",
         "0.7635983263598326"
        ],
        [
         "2",
         "[123, 318, 193]",
         "Tanh",
         "0.5",
         "SGD",
         "0.01888414408860807",
         "1e-06",
         "0.8",
         "512",
         "True",
         "kaiming_normal",
         "step",
         "{'step_size': 20, 'gamma': 0.1}",
         "0.5810489288295608",
         "0.6883184913567313",
         "0.48062342405319214",
         "0.7635983263598326"
        ],
        [
         "3",
         "[416, 486, 246, 511, 413, 165]",
         "ReLU",
         "0.4",
         "RMSprop",
         "0.00021157007147045822",
         "0.0001",
         null,
         "32",
         "False",
         "xavier_normal",
         "none",
         "{}",
         "0.42718695237600346",
         "0.7967522262964903",
         "0.43681867850874256",
         "0.7594142259414226"
        ],
        [
         "4",
         "[410, 475, 458, 404, 406, 283]",
         "LeakyReLU",
         "0.2",
         "AdamW",
         "0.0002279370405507212",
         "0.0",
         null,
         "256",
         "True",
         "kaiming_normal",
         "none",
         "{}",
         "0.4970914293734299",
         "0.7579884756416972",
         "0.45968513122163557",
         "0.7573221757322176"
        ],
        [
         "5",
         "[298, 419, 41, 166, 114]",
         "ELU",
         "0.0",
         "Adam",
         "0.003956468942179006",
         "0.01",
         null,
         "128",
         "False",
         "kaiming_uniform",
         "none",
         "{}",
         "0.3958168867497372",
         "0.8056574122577266",
         "0.4582389742759481",
         "0.7573221757322176"
        ],
        [
         "6",
         "[224, 317, 235, 193, 153, 87, 312]",
         "ELU",
         "0.3",
         "AdamW",
         "0.00039841972428913356",
         "0.0001",
         null,
         "64",
         "False",
         "kaiming_normal",
         "exponential",
         "{'gamma': 0.95}",
         "0.5998519065181518",
         "0.7223677317967522",
         "0.46331959551348345",
         "0.7552301255230126"
        ],
        [
         "7",
         "[155, 381]",
         "ELU",
         "0.3",
         "Adam",
         "0.0010876177618100746",
         "0.001",
         null,
         "32",
         "False",
         "xavier_normal",
         "cosine",
         "{'T_max': 100}",
         "0.39127433813636125",
         "0.8082765845992667",
         "0.4612460041644683",
         "0.7552301255230126"
        ],
        [
         "8",
         "[140, 509, 271, 134]",
         "LeakyReLU",
         "0.3",
         "Adam",
         "0.00023297993731527828",
         "0.01",
         null,
         "64",
         "False",
         "xavier_uniform",
         "exponential",
         "{'gamma': 0.9}",
         "0.46016826022039725",
         "0.7689889994761655",
         "0.45232951815657035",
         "0.7531380753138075"
        ],
        [
         "9",
         "[351, 472]",
         "LeakyReLU",
         "0.0",
         "Adam",
         "0.01501470581248169",
         "0.01",
         null,
         "64",
         "True",
         "kaiming_normal",
         "exponential",
         "{'gamma': 0.99}",
         "0.45616462150751574",
         "0.7778941854374017",
         "0.4628805844853613",
         "0.7510460251046025"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation_fn</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>optimizer_type</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>momentum</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>use_skip_connections</th>\n",
       "      <th>initializer</th>\n",
       "      <th>lr_scheduler</th>\n",
       "      <th>scheduler_params</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[311, 52, 292, 134, 237, 51]</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>cosine</td>\n",
       "      <td>{'T_max': 50}</td>\n",
       "      <td>0.405307</td>\n",
       "      <td>0.805657</td>\n",
       "      <td>0.449841</td>\n",
       "      <td>0.765690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[386, 313, 24, 355, 91, 227]</td>\n",
       "      <td>Sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>step</td>\n",
       "      <td>{'step_size': 20, 'gamma': 0.5}</td>\n",
       "      <td>0.444936</td>\n",
       "      <td>0.801991</td>\n",
       "      <td>0.462744</td>\n",
       "      <td>0.763598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[123, 318, 193]</td>\n",
       "      <td>Tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.018884</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_normal</td>\n",
       "      <td>step</td>\n",
       "      <td>{'step_size': 20, 'gamma': 0.1}</td>\n",
       "      <td>0.581049</td>\n",
       "      <td>0.688318</td>\n",
       "      <td>0.480623</td>\n",
       "      <td>0.763598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[416, 486, 246, 511, 413, 165]</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>0.4</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>xavier_normal</td>\n",
       "      <td>none</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.427187</td>\n",
       "      <td>0.796752</td>\n",
       "      <td>0.436819</td>\n",
       "      <td>0.759414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[410, 475, 458, 404, 406, 283]</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>0.2</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_normal</td>\n",
       "      <td>none</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.497091</td>\n",
       "      <td>0.757988</td>\n",
       "      <td>0.459685</td>\n",
       "      <td>0.757322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[298, 419, 41, 166, 114]</td>\n",
       "      <td>ELU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>kaiming_uniform</td>\n",
       "      <td>none</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.395817</td>\n",
       "      <td>0.805657</td>\n",
       "      <td>0.458239</td>\n",
       "      <td>0.757322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[224, 317, 235, 193, 153, 87, 312]</td>\n",
       "      <td>ELU</td>\n",
       "      <td>0.3</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>kaiming_normal</td>\n",
       "      <td>exponential</td>\n",
       "      <td>{'gamma': 0.95}</td>\n",
       "      <td>0.599852</td>\n",
       "      <td>0.722368</td>\n",
       "      <td>0.463320</td>\n",
       "      <td>0.755230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[155, 381]</td>\n",
       "      <td>ELU</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>xavier_normal</td>\n",
       "      <td>cosine</td>\n",
       "      <td>{'T_max': 100}</td>\n",
       "      <td>0.391274</td>\n",
       "      <td>0.808277</td>\n",
       "      <td>0.461246</td>\n",
       "      <td>0.755230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[140, 509, 271, 134]</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>xavier_uniform</td>\n",
       "      <td>exponential</td>\n",
       "      <td>{'gamma': 0.9}</td>\n",
       "      <td>0.460168</td>\n",
       "      <td>0.768989</td>\n",
       "      <td>0.452330</td>\n",
       "      <td>0.753138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[351, 472]</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiming_normal</td>\n",
       "      <td>exponential</td>\n",
       "      <td>{'gamma': 0.99}</td>\n",
       "      <td>0.456165</td>\n",
       "      <td>0.777894</td>\n",
       "      <td>0.462881</td>\n",
       "      <td>0.751046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        hidden_layers activation_fn  dropout_rate  \\\n",
       "0        [311, 52, 292, 134, 237, 51]          ReLU           0.2   \n",
       "1        [386, 313, 24, 355, 91, 227]       Sigmoid           0.3   \n",
       "2                     [123, 318, 193]          Tanh           0.5   \n",
       "3      [416, 486, 246, 511, 413, 165]          ReLU           0.4   \n",
       "4      [410, 475, 458, 404, 406, 283]     LeakyReLU           0.2   \n",
       "5            [298, 419, 41, 166, 114]           ELU           0.0   \n",
       "6  [224, 317, 235, 193, 153, 87, 312]           ELU           0.3   \n",
       "7                          [155, 381]           ELU           0.3   \n",
       "8                [140, 509, 271, 134]     LeakyReLU           0.3   \n",
       "9                          [351, 472]     LeakyReLU           0.0   \n",
       "\n",
       "  optimizer_type  learning_rate  weight_decay  momentum  batch_size  \\\n",
       "0        RMSprop       0.000812      0.001000       NaN         512   \n",
       "1           Adam       0.003550      0.000001       NaN          64   \n",
       "2            SGD       0.018884      0.000001       0.8         512   \n",
       "3        RMSprop       0.000212      0.000100       NaN          32   \n",
       "4          AdamW       0.000228      0.000000       NaN         256   \n",
       "5           Adam       0.003956      0.010000       NaN         128   \n",
       "6          AdamW       0.000398      0.000100       NaN          64   \n",
       "7           Adam       0.001088      0.001000       NaN          32   \n",
       "8           Adam       0.000233      0.010000       NaN          64   \n",
       "9           Adam       0.015015      0.010000       NaN          64   \n",
       "\n",
       "   use_skip_connections      initializer lr_scheduler  \\\n",
       "0                  True  kaiming_uniform       cosine   \n",
       "1                  True   xavier_uniform         step   \n",
       "2                  True   kaiming_normal         step   \n",
       "3                 False    xavier_normal         none   \n",
       "4                  True   kaiming_normal         none   \n",
       "5                 False  kaiming_uniform         none   \n",
       "6                 False   kaiming_normal  exponential   \n",
       "7                 False    xavier_normal       cosine   \n",
       "8                 False   xavier_uniform  exponential   \n",
       "9                  True   kaiming_normal  exponential   \n",
       "\n",
       "                  scheduler_params  train_loss  train_acc  val_loss   val_acc  \n",
       "0                    {'T_max': 50}    0.405307   0.805657  0.449841  0.765690  \n",
       "1  {'step_size': 20, 'gamma': 0.5}    0.444936   0.801991  0.462744  0.763598  \n",
       "2  {'step_size': 20, 'gamma': 0.1}    0.581049   0.688318  0.480623  0.763598  \n",
       "3                               {}    0.427187   0.796752  0.436819  0.759414  \n",
       "4                               {}    0.497091   0.757988  0.459685  0.757322  \n",
       "5                               {}    0.395817   0.805657  0.458239  0.757322  \n",
       "6                  {'gamma': 0.95}    0.599852   0.722368  0.463320  0.755230  \n",
       "7                   {'T_max': 100}    0.391274   0.808277  0.461246  0.755230  \n",
       "8                   {'gamma': 0.9}    0.460168   0.768989  0.452330  0.753138  \n",
       "9                  {'gamma': 0.99}    0.456165   0.777894  0.462881  0.751046  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5aaa08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(5).to_csv('results_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4255428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{longtable}{llrlrrrrrlllrrrr}\n",
      "\\toprule\n",
      "hidden_layers & activation_fn & dropout_rate & optimizer_type & learning_rate & weight_decay & momentum & batch_size & use_skip_connections & initializer & lr_scheduler & scheduler_params & train_loss & train_acc & val_loss & val_acc \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\toprule\n",
      "hidden_layers & activation_fn & dropout_rate & optimizer_type & learning_rate & weight_decay & momentum & batch_size & use_skip_connections & initializer & lr_scheduler & scheduler_params & train_loss & train_acc & val_loss & val_acc \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{16}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "[311, 52, 292, 134, 237, 51] & ReLU & 0.200000 & RMSprop & 0.000812 & 0.001000 & NaN & 512 & True & kaiming_uniform & cosine & {'T_max': 50} & 0.405307 & 0.805657 & 0.449841 & 0.765690 \\\\\n",
      "[386, 313, 24, 355, 91, 227] & Sigmoid & 0.300000 & Adam & 0.003550 & 0.000001 & NaN & 64 & True & xavier_uniform & step & {'step_size': 20, 'gamma': 0.5} & 0.444936 & 0.801991 & 0.462744 & 0.763598 \\\\\n",
      "[123, 318, 193] & Tanh & 0.500000 & SGD & 0.018884 & 0.000001 & 0.800000 & 512 & True & kaiming_normal & step & {'step_size': 20, 'gamma': 0.1} & 0.581049 & 0.688318 & 0.480623 & 0.763598 \\\\\n",
      "[416, 486, 246, 511, 413, 165] & ReLU & 0.400000 & RMSprop & 0.000212 & 0.000100 & NaN & 32 & False & xavier_normal & none & {} & 0.427187 & 0.796752 & 0.436819 & 0.759414 \\\\\n",
      "[410, 475, 458, 404, 406, 283] & LeakyReLU & 0.200000 & AdamW & 0.000228 & 0.000000 & NaN & 256 & True & kaiming_normal & none & {} & 0.497091 & 0.757988 & 0.459685 & 0.757322 \\\\\n",
      "[298, 419, 41, 166, 114] & ELU & 0.000000 & Adam & 0.003956 & 0.010000 & NaN & 128 & False & kaiming_uniform & none & {} & 0.395817 & 0.805657 & 0.458239 & 0.757322 \\\\\n",
      "[224, 317, 235, 193, 153, 87, 312] & ELU & 0.300000 & AdamW & 0.000398 & 0.000100 & NaN & 64 & False & kaiming_normal & exponential & {'gamma': 0.95} & 0.599852 & 0.722368 & 0.463320 & 0.755230 \\\\\n",
      "[155, 381] & ELU & 0.300000 & Adam & 0.001088 & 0.001000 & NaN & 32 & False & xavier_normal & cosine & {'T_max': 100} & 0.391274 & 0.808277 & 0.461246 & 0.755230 \\\\\n",
      "[140, 509, 271, 134] & LeakyReLU & 0.300000 & Adam & 0.000233 & 0.010000 & NaN & 64 & False & xavier_uniform & exponential & {'gamma': 0.9} & 0.460168 & 0.768989 & 0.452330 & 0.753138 \\\\\n",
      "[351, 472] & LeakyReLU & 0.000000 & Adam & 0.015015 & 0.010000 & NaN & 64 & True & kaiming_normal & exponential & {'gamma': 0.99} & 0.456165 & 0.777894 & 0.462881 & 0.751046 \\\\\n",
      "[380, 193] & Sigmoid & 0.400000 & AdamW & 0.022875 & 0.000010 & NaN & 64 & False & xavier_normal & exponential & {'gamma': 0.99} & 0.427624 & 0.801991 & 0.474588 & 0.746862 \\\\\n",
      "[80, 397, 245] & Tanh & 0.200000 & SGD & 0.012567 & 0.000000 & 0.800000 & 128 & True & kaiming_uniform & step & {'step_size': 5, 'gamma': 0.9} & 0.453450 & 0.784180 & 0.483016 & 0.744770 \\\\\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_df.to_latex(index=False, longtable=True, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4220afb",
   "metadata": {},
   "source": [
    "# Train N top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a98802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ebe.create_model_from_row(results_df.iloc[0], \n",
    "                                  input_size=input_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99c1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(results_df.loc[0, 'batch_size']) # batch size for training the model\n",
    "# For training a model, DataLoader is needed\n",
    "train_loader = ebe.create_dataloaders(X=X_train, y=y_train, \n",
    "                       batch_size=batch_size)\n",
    "val_loader = ebe.create_dataloaders(X=X_val, y=y_val, \n",
    "                       batch_size=batch_size)\n",
    "test_loader = ebe.create_dataloaders(X=X_test, y=y_test, \n",
    "                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "557c196b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc found: 0.7615062761506276\n",
      "Epoch 1: Train Loss=2.3365, Train Acc=0.5359, Val Loss=0.6582, Val Acc=0.7615\n",
      "Epoch 2: Train Loss=0.6479, Train Acc=0.6815, Val Loss=0.6390, Val Acc=0.7552\n",
      "Epoch 3: Train Loss=0.6241, Train Acc=0.7266, Val Loss=0.6185, Val Acc=0.7552\n",
      "Epoch 4: Train Loss=0.6088, Train Acc=0.7480, Val Loss=0.6072, Val Acc=0.7552\n",
      "Epoch 5: Train Loss=0.5811, Train Acc=0.7622, Val Loss=0.5949, Val Acc=0.7573\n",
      "Epoch 6: Train Loss=0.5686, Train Acc=0.7742, Val Loss=0.5757, Val Acc=0.7573\n",
      "Epoch 7: Train Loss=0.5351, Train Acc=0.7878, Val Loss=0.5408, Val Acc=0.7552\n",
      "New best acc found: 0.7656903765690377\n",
      "Epoch 8: Train Loss=0.4707, Train Acc=0.8093, Val Loss=0.4703, Val Acc=0.7657\n",
      "Epoch 9: Train Loss=0.4311, Train Acc=0.8125, Val Loss=0.4537, Val Acc=0.7615\n",
      "Epoch 10: Train Loss=0.3805, Train Acc=0.8298, Val Loss=0.4532, Val Acc=0.7636\n",
      "New best acc found: 0.7698744769874477\n",
      "Epoch 11: Train Loss=0.3569, Train Acc=0.8470, Val Loss=0.4649, Val Acc=0.7699\n",
      "Epoch 12: Train Loss=0.3355, Train Acc=0.8580, Val Loss=0.4818, Val Acc=0.7573\n",
      "Epoch 13: Train Loss=0.3206, Train Acc=0.8717, Val Loss=0.4916, Val Acc=0.7699\n",
      "Epoch 14: Train Loss=0.2972, Train Acc=0.8790, Val Loss=0.4923, Val Acc=0.7699\n",
      "Epoch 15: Train Loss=0.2904, Train Acc=0.8759, Val Loss=0.5043, Val Acc=0.7594\n",
      "Epoch 16: Train Loss=0.2477, Train Acc=0.9052, Val Loss=0.5562, Val Acc=0.7364\n",
      "Epoch 17: Train Loss=0.2254, Train Acc=0.9125, Val Loss=0.6183, Val Acc=0.7615\n",
      "Epoch 18: Train Loss=0.2421, Train Acc=0.9041, Val Loss=0.5417, Val Acc=0.7594\n",
      "Epoch 19: Train Loss=0.1894, Train Acc=0.9303, Val Loss=0.5972, Val Acc=0.7427\n",
      "Epoch 20: Train Loss=0.1889, Train Acc=0.9261, Val Loss=0.6188, Val Acc=0.7615\n",
      "Epoch 21: Train Loss=0.1806, Train Acc=0.9309, Val Loss=0.6158, Val Acc=0.7699\n",
      "Epoch 22: Train Loss=0.1680, Train Acc=0.9345, Val Loss=0.6745, Val Acc=0.7155\n",
      "Epoch 23: Train Loss=0.1569, Train Acc=0.9455, Val Loss=0.6582, Val Acc=0.7364\n",
      "Epoch 24: Train Loss=0.1290, Train Acc=0.9570, Val Loss=0.7108, Val Acc=0.7364\n",
      "Epoch 25: Train Loss=0.1450, Train Acc=0.9471, Val Loss=0.6875, Val Acc=0.7699\n",
      "Epoch 26: Train Loss=0.1425, Train Acc=0.9466, Val Loss=0.7138, Val Acc=0.7657\n",
      "Epoch 27: Train Loss=0.1541, Train Acc=0.9424, Val Loss=0.6909, Val Acc=0.7448\n",
      "Epoch 28: Train Loss=0.1082, Train Acc=0.9623, Val Loss=0.7290, Val Acc=0.7531\n",
      "Epoch 29: Train Loss=0.1080, Train Acc=0.9602, Val Loss=0.7402, Val Acc=0.7552\n",
      "Epoch 30: Train Loss=0.1161, Train Acc=0.9623, Val Loss=0.7466, Val Acc=0.7594\n",
      "Epoch 31: Train Loss=0.0914, Train Acc=0.9665, Val Loss=0.8066, Val Acc=0.7490\n",
      "Epoch 32: Train Loss=0.0898, Train Acc=0.9691, Val Loss=0.8440, Val Acc=0.7510\n",
      "Epoch 33: Train Loss=0.0978, Train Acc=0.9628, Val Loss=0.8108, Val Acc=0.7552\n",
      "Epoch 34: Train Loss=0.0894, Train Acc=0.9686, Val Loss=0.8316, Val Acc=0.7510\n",
      "Epoch 35: Train Loss=0.0906, Train Acc=0.9733, Val Loss=0.8163, Val Acc=0.7490\n",
      "Epoch 36: Train Loss=0.0858, Train Acc=0.9707, Val Loss=0.8910, Val Acc=0.7510\n",
      "Epoch 37: Train Loss=0.0769, Train Acc=0.9743, Val Loss=0.8925, Val Acc=0.7490\n",
      "Epoch 38: Train Loss=0.0813, Train Acc=0.9701, Val Loss=0.9239, Val Acc=0.7448\n",
      "Epoch 39: Train Loss=0.0603, Train Acc=0.9790, Val Loss=0.9412, Val Acc=0.7552\n",
      "Epoch 40: Train Loss=0.0542, Train Acc=0.9843, Val Loss=0.9470, Val Acc=0.7469\n",
      "Epoch 41: Train Loss=0.0746, Train Acc=0.9749, Val Loss=0.9475, Val Acc=0.7615\n",
      "Epoch 42: Train Loss=0.0565, Train Acc=0.9796, Val Loss=0.9439, Val Acc=0.7448\n",
      "Epoch 43: Train Loss=0.0700, Train Acc=0.9764, Val Loss=0.9341, Val Acc=0.7469\n",
      "Epoch 44: Train Loss=0.0573, Train Acc=0.9806, Val Loss=1.0051, Val Acc=0.7490\n",
      "Epoch 45: Train Loss=0.0505, Train Acc=0.9843, Val Loss=0.9937, Val Acc=0.7469\n",
      "Epoch 46: Train Loss=0.0695, Train Acc=0.9764, Val Loss=0.9785, Val Acc=0.7573\n",
      "Epoch 47: Train Loss=0.0630, Train Acc=0.9775, Val Loss=0.9708, Val Acc=0.7406\n",
      "Epoch 48: Train Loss=0.0534, Train Acc=0.9817, Val Loss=0.9469, Val Acc=0.7406\n",
      "Epoch 49: Train Loss=0.0612, Train Acc=0.9806, Val Loss=0.9558, Val Acc=0.7406\n",
      "Epoch 50: Train Loss=0.0442, Train Acc=0.9859, Val Loss=1.0110, Val Acc=0.7573\n",
      "Epoch 51: Train Loss=0.0553, Train Acc=0.9822, Val Loss=1.0131, Val Acc=0.7406\n",
      "Epoch 52: Train Loss=0.0450, Train Acc=0.9874, Val Loss=1.0368, Val Acc=0.7385\n",
      "Epoch 53: Train Loss=0.0615, Train Acc=0.9801, Val Loss=0.9783, Val Acc=0.7573\n",
      "Epoch 54: Train Loss=0.0446, Train Acc=0.9843, Val Loss=1.0148, Val Acc=0.7510\n",
      "Epoch 55: Train Loss=0.0509, Train Acc=0.9848, Val Loss=1.0231, Val Acc=0.7552\n",
      "Epoch 56: Train Loss=0.0513, Train Acc=0.9848, Val Loss=1.0163, Val Acc=0.7552\n",
      "Epoch 57: Train Loss=0.0409, Train Acc=0.9869, Val Loss=1.0304, Val Acc=0.7531\n",
      "Epoch 58: Train Loss=0.0392, Train Acc=0.9874, Val Loss=1.0451, Val Acc=0.7385\n",
      "Epoch 59: Train Loss=0.0463, Train Acc=0.9848, Val Loss=1.0763, Val Acc=0.7448\n",
      "Epoch 60: Train Loss=0.0573, Train Acc=0.9822, Val Loss=1.0080, Val Acc=0.7531\n",
      "Epoch 61: Train Loss=0.0505, Train Acc=0.9827, Val Loss=1.0571, Val Acc=0.7678\n",
      "Early stopping triggered after 61 epochs.\n"
     ]
    }
   ],
   "source": [
    "best_train_loss, best_train_acc, best_val_loss, best_val_acc = best_model.es_train(train_loader=train_loader, val_loader=val_loader,\n",
    "                    es_patience=50, # epochs without improvement\n",
    "                    max_epochs=1000, # cap for epochs\n",
    "                    verbose=True, # print training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04978b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4356, Test accuracy: 0.7990\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(test_loader)\n",
    "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c287db",
   "metadata": {},
   "source": [
    "Now it can be used as a regular nn.Module model, as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = best_model.to(device)\n",
    "best_model.eval()\n",
    "X_test_tensor = X_test.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = best_model(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted_classes = torch.max(predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a09f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "        0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
